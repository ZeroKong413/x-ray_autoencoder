{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19Mo4QYtgcml",
        "outputId": "11889c07-9c0b-4e53-dff1-aeb822762c42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "10/10 [==============================] - 24s 2s/step - loss: 0.0147\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 27s 3s/step - loss: 0.0088\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.0081\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.0067\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.0073\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.0083\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 23s 2s/step - loss: 0.0065\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.0058\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.0026\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.0010\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 5.5254e-04\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 1.7119e-04\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 6.9264e-05\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 2.6095e-05\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 9.4510e-06\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 4.1055e-06\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 1.7873e-06\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 6.4699e-07\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 2.9912e-07\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 1.5946e-07\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 7.7605e-08\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 23s 2s/step - loss: 5.3309e-08\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 23s 2s/step - loss: 4.2647e-08\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 22s 2s/step - loss: 2.5701e-08\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 9.4243e-09\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 22s 2s/step - loss: 4.6078e-09\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 20s 2s/step - loss: 2.6792e-09\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 20s 2s/step - loss: 1.6634e-09\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 20s 2s/step - loss: 8.9381e-10\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 20s 2s/step - loss: 5.9693e-10\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 20s 2s/step - loss: 3.7718e-10\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 20s 2s/step - loss: 2.1596e-10\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 20s 2s/step - loss: 1.7830e-10\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 20s 2s/step - loss: 1.4196e-10\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 1.3112e-10\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 20s 2s/step - loss: 6.4165e-11\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 4.3882e-11\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 2.7110e-11\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 20s 2s/step - loss: 1.5039e-11\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 20s 2s/step - loss: 1.0919e-11\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 20s 2s/step - loss: 7.0121e-12\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 5.0997e-12\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 20s 2s/step - loss: 3.4546e-12\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 20s 2s/step - loss: 2.1820e-12\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 1.5163e-12\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 9.0636e-13\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 6.2504e-13\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 3.9020e-13\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 2.5236e-13\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 21s 2s/step - loss: 1.5958e-13\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# 훈련에 사용할 이미지들을 지정\n",
        "image_paths = ['image123.jpg', 'image321.jpg', 'imageee.jpg', 'imageee1.jpg', 'imageeee.jpg']\n",
        "all_images = []\n",
        "\n",
        "# 한 이미지를 20번씩 사용함\n",
        "for path in image_paths:\n",
        "    img = tf.keras.preprocessing.image.load_img(path, target_size=(200, 200))\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    for _ in range(20):\n",
        "        all_images.append(img_array)\n",
        "\n",
        "# 이미지 픽셀 값(0~255)을 0~1 사이로 정규화\n",
        "all_images_array = np.array(all_images) / 255.0\n",
        "\n",
        "# 오토인코더 모델을 정의\n",
        "input_img = Input(shape=(200, 200, 3))\n",
        "x = Flatten()(input_img)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "encoded = Dense(512, activation='relu')(x)\n",
        "\n",
        "x = Dense(1024, activation='relu')(encoded)\n",
        "x = Dense(200*200*3, activation='sigmoid')(x)\n",
        "decoded = Reshape((200, 200, 3))(x)\n",
        "\n",
        "# 오토인코더\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# 4. 모델 컴파일 및 학습\n",
        "\n",
        "# 학습을 할때 10번 이상 loss 값이 안바뀌면 중간에 학습을 일찍 중지시킴\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=10, verbose=1)\n",
        "\n",
        "# 모델 컴파일\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# 모델 학습\n",
        "autoencoder.fit(all_images_array, all_images_array, epochs=50, batch_size=10, callbacks=[early_stopping])\n",
        "\n",
        "# 학습된 모델을 저장\n",
        "tf.keras.models.save_model(autoencoder, 'autoencoder_saved_model2')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장된 오토인코더 모델 불러오기\n",
        "loaded_model = tf.keras.models.load_model('autoencoder_saved_model2')\n",
        "\n",
        "# 테스트에 사용할 이미지를 로드하고 전처리\n",
        "img_path = 'error.jpg'\n",
        "img = tf.keras.preprocessing.image.load_img(img_path, target_size=(200, 200))\n",
        "img_array = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# 이미지 재구성\n",
        "reconstructed = loaded_model.predict(img_array)\n",
        "\n",
        "# 재구성 오차를 계산\n",
        "mse = np.mean(np.square(img_array - reconstructed))\n",
        "\n",
        "# 이상 탐지\n",
        "threshold = 0.01  # 예시임계값, 너무 낮추면 정상을 못찾아냄, 너무 높이면 다 정상이라고 함\n",
        "if mse > threshold:\n",
        "    print(\"이상 데이터입니다.\")\n",
        "else:\n",
        "    print(\"정상 데이터입니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF4jp-Ullr9u",
        "outputId": "04c3444b-1dbf-463c-8fc2-f3a64c70e1d9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 131ms/step\n",
            "이상 데이터입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트에 사용할 이미지를 로드하고 전처리\n",
        "img_path = 'image09.jpg'\n",
        "img = tf.keras.preprocessing.image.load_img(img_path, target_size=(200, 200))\n",
        "img_array = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# 이미지 재구성\n",
        "reconstructed = loaded_model.predict(img_array)\n",
        "\n",
        "# 재구성 오차를 계산\n",
        "mse = np.mean(np.square(img_array - reconstructed))\n",
        "\n",
        "# 이상 탐지\n",
        "threshold = 0.02  # 예시임계값, 너무 높이면 다 정상이라고 함\n",
        "if mse > threshold:\n",
        "    print(\"이상 데이터입니다.\")\n",
        "else:\n",
        "    print(\"정상 데이터입니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L82_fRM5mv80",
        "outputId": "a7d686a6-1f6f-4359-ac2b-b2baf3f6e99f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 99ms/step\n",
            "이상 데이터입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 구조 정의\n",
        "input_img = Input(shape=(200, 200, 3))\n",
        "x = Flatten()(input_img)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "encoded = Dense(512, activation='relu')(x)\n",
        "x = Dense(1024, activation='relu')(encoded)\n",
        "x = Dense(200*200*3, activation='sigmoid')(x)\n",
        "decoded = Reshape((200, 200, 3))(x)\n",
        "autoencoder_temp = Model(input_img, decoded)\n",
        "\n",
        "autoencoder_temp.load_weights('autoencoder_saved_model2/variables/variables')\n",
        "\n",
        "\n",
        "# 2. \"error.jpg\" 이미지 불러오기 및 전처리\n",
        "error_img = tf.keras.preprocessing.image.load_img('imageee.jpg', target_size=(200, 200))\n",
        "error_img_array = tf.keras.preprocessing.image.img_to_array(error_img) / 255.0\n",
        "error_img_array = np.expand_dims(error_img_array, axis=0)\n",
        "\n",
        "# 3. 이미지를 오토인코더에 통과시키기\n",
        "reconstructed_img_array = autoencoder_temp.predict(error_img_array)\n",
        "\n",
        "# 4. 원본 이미지와 재구성된 이미지 사이의 재구성 오차 계산\n",
        "reconstruction_error = np.mean(np.square(error_img_array - reconstructed_img_array))\n",
        "\n",
        "reconstruction_error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHhKUC_dy51f",
        "outputId": "805a6f37-284c-40de-95ed-9fb4701c600f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 120ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.6746653e-14"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 구조 정의\n",
        "input_img = Input(shape=(200, 200, 3))\n",
        "x = Flatten()(input_img)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "encoded = Dense(512, activation='relu')(x)\n",
        "x = Dense(1024, activation='relu')(encoded)\n",
        "x = Dense(200*200*3, activation='sigmoid')(x)\n",
        "decoded = Reshape((200, 200, 3))(x)\n",
        "autoencoder_temp = Model(input_img, decoded)\n",
        "\n",
        "autoencoder_temp.load_weights('autoencoder_saved_model2/variables/variables')\n",
        "\n",
        "\n",
        "# 2. \"error.jpg\" 이미지 불러오기 및 전처리\n",
        "error_img = tf.keras.preprocessing.image.load_img('image09.jpg', target_size=(200, 200))\n",
        "error_img_array = tf.keras.preprocessing.image.img_to_array(error_img) / 255.0\n",
        "error_img_array = np.expand_dims(error_img_array, axis=0)\n",
        "\n",
        "# 3. 이미지를 오토인코더에 통과시키기\n",
        "reconstructed_img_array = autoencoder_temp.predict(error_img_array)\n",
        "\n",
        "# 4. 원본 이미지와 재구성된 이미지 사이의 재구성 오차 계산\n",
        "reconstruction_error = np.mean(np.square(error_img_array - reconstructed_img_array))\n",
        "\n",
        "reconstruction_error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTBVS-zM0PcF",
        "outputId": "c01d8820-ee73-4add-a3ab-c008c39b377b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 133ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.024797756"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# 1. 데이터 준비\n",
        "image_paths = ['image123.jpg', 'image321.jpg', 'imageee.jpg', 'imageee1.jpg', 'imageeee.jpg']\n",
        "all_images = []\n",
        "\n",
        "for path in image_paths:\n",
        "    img = tf.keras.preprocessing.image.load_img(path, target_size=(200, 200))\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    for _ in range(20):\n",
        "        all_images.append(img_array)\n",
        "\n",
        "all_images_array = np.array(all_images) / 255.0\n",
        "\n",
        "# 2. CNN 오토인코더 모델 정의\n",
        "input_img = Input(shape=(200, 200, 3))\n",
        "\n",
        "# Encoder\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# Decoder\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "# 학습을 할때 10번 이상 loss 값이 안바뀌면 중간에 학습을 일찍 중지시킴\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=10, verbose=1)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# 3. 모델 학습\n",
        "autoencoder.fit(all_images_array, all_images_array, epochs=50, batch_size=10, callbacks=[early_stopping])\n",
        "\n",
        "# 4. 학습된 모델 저장\n",
        "autoencoder.save('autoencoder_cnn_model')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5HuxLv-3Gb7",
        "outputId": "b9a0a276-c209-42b0-ad24-d4ca759f891f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.0218\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 10s 1s/step - loss: 0.0178\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 9s 895ms/step - loss: 0.0128\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 10s 957ms/step - loss: 0.0089\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 10s 998ms/step - loss: 0.0062\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 10s 999ms/step - loss: 0.0045\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 10s 990ms/step - loss: 0.0028\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 9s 921ms/step - loss: 0.0019\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 10s 927ms/step - loss: 0.0016\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 10s 1s/step - loss: 0.0012\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 10s 1s/step - loss: 9.3505e-04\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 10s 1s/step - loss: 8.0636e-04\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 10s 979ms/step - loss: 7.2200e-04\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 9s 920ms/step - loss: 6.6247e-04\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 10s 998ms/step - loss: 6.1345e-04\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 10s 1s/step - loss: 5.6860e-04\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 10s 998ms/step - loss: 5.3429e-04\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 10s 993ms/step - loss: 5.0568e-04\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 9s 916ms/step - loss: 4.7331e-04\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 10s 963ms/step - loss: 4.5922e-04\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 10s 1s/step - loss: 5.2159e-04\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 10s 991ms/step - loss: 4.6745e-04\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 10s 997ms/step - loss: 4.6099e-04\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 9s 928ms/step - loss: 4.0810e-04\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 10s 932ms/step - loss: 4.0594e-04\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 10s 1s/step - loss: 3.6298e-04\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 10s 1s/step - loss: 3.5200e-04\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 10s 1s/step - loss: 3.2485e-04\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 10s 1s/step - loss: 3.8967e-04\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 9s 918ms/step - loss: 3.4403e-04\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 10s 979ms/step - loss: 2.9196e-04\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 10s 1s/step - loss: 2.5874e-04\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 10s 1s/step - loss: 2.3693e-04\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 10s 1s/step - loss: 2.3683e-04\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 10s 1s/step - loss: 2.1947e-04\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 9s 935ms/step - loss: 2.1198e-04\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 10s 982ms/step - loss: 3.5734e-04\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 10s 1s/step - loss: 2.5159e-04\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 10s 1s/step - loss: 2.1268e-04\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 10s 1s/step - loss: 2.1439e-04\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 9s 910ms/step - loss: 1.9386e-04\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 10s 947ms/step - loss: 1.8354e-04\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 10s 996ms/step - loss: 1.8456e-04\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 10s 1000ms/step - loss: 1.6709e-04\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 10s 996ms/step - loss: 1.6964e-04\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 9s 942ms/step - loss: 2.1518e-04\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 10s 910ms/step - loss: 1.9137e-04\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 10s 994ms/step - loss: 1.6286e-04\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 10s 981ms/step - loss: 1.5946e-04\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 10s 991ms/step - loss: 1.5222e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장된 오토인코더 모델 불러오기\n",
        "loaded_model = tf.keras.models.load_model('autoencoder_cnn_model')\n"
      ],
      "metadata": {
        "id": "08IlarK43GeO"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트에 사용할 이미지를 로드하고 전처리\n",
        "img_path = 'image09.jpg'\n",
        "img = tf.keras.preprocessing.image.load_img(img_path, target_size=(200, 200))\n",
        "img_array = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# 이미지 재구성\n",
        "reconstructed = loaded_model.predict(img_array)\n",
        "\n",
        "# 재구성 오차를 계산\n",
        "mse = np.mean(np.square(img_array - reconstructed))\n",
        "\n",
        "# 이상 탐지\n",
        "threshold = 0.00019  # 예시임계값, 너무 낮추면 정상을 못찾아냄, 너무 높이면 다 정상이라고 함\n",
        "if mse > threshold:\n",
        "    print(\"이상 데이터입니다.\")\n",
        "else:\n",
        "    print(\"정상 데이터입니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwVCFWy93Ggc",
        "outputId": "f163e337-0c1a-4551-86fb-66a0aa82f5d3"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 38ms/step\n",
            "정상 데이터입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_img = Input(shape=(200, 200, 3))\n",
        "\n",
        "# Encoder\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# Decoder\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "autoencoder_temp = Model(input_img, decoded)\n",
        "\n",
        "autoencoder_temp.load_weights('autoencoder_cnn_model/variables/variables')\n",
        "\n",
        "\n",
        "# 2. \"error.jpg\" 이미지 불러오기 및 전처리\n",
        "error_img = tf.keras.preprocessing.image.load_img('image09.jpg', target_size=(200, 200))\n",
        "error_img_array = tf.keras.preprocessing.image.img_to_array(error_img) / 255.0\n",
        "error_img_array = np.expand_dims(error_img_array, axis=0)\n",
        "\n",
        "# 3. 이미지를 오토인코더에 통과시키기\n",
        "reconstructed_img_array = autoencoder_temp.predict(error_img_array)\n",
        "\n",
        "# 4. 원본 이미지와 재구성된 이미지 사이의 재구성 오차 계산\n",
        "reconstruction_error = np.mean(np.square(error_img_array - reconstructed_img_array))\n",
        "\n",
        "reconstruction_error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xpaot5cn3GmU",
        "outputId": "fcb961d7-60c6-4c76-e82a-d161f61a3c4a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 121ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00018554466"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    }
  ]
}